# Mejoras de Precisi√≥n - Fase 1 ‚úÖ

## Resumen de Cambios Implementados

### 1. ‚úÖ Headers HTTP Mejorados
**Archivos modificados:**
- `scrapers/generic_scrapers.py`
- `scrapers/graphql_scraper.py`

**Cambios:**
- Headers completos simulando navegador Chrome real
- Incluye: User-Agent, Accept, Accept-Language, Sec-Fetch-*, etc.
- Headers espec√≠ficos para GraphQL (Origin, Referer)

**Impacto:** Reduce la detecci√≥n de bot b√°sica.

---

### 2. ‚úÖ Filtro de Categor√≠a Eliminado
**Archivo modificado:**
- `config_sitios.json`

**Cambio:**
```json
// ANTES - Solo buscaba en celulares
"selectedFacets": [
  {"key": "category-2", "value": "celulares"},  ‚ùå
  ...
]

// DESPU√âS - Busca en todas las categor√≠as
"selectedFacets": [
  {"key": "channel", "value": "..."},  ‚úÖ
  {"key": "locale", "value": "es-CO"}
]
```

**Impacto:** Ahora puede buscar lavadoras, neveras, y cualquier producto, no solo celulares.

---

### 3. ‚úÖ Sistema de Scoring de Relevancia
**Archivo nuevo:**
- `scrapers/text_utils.py`

**Funcionalidad:**
- `normalize_text()`: Normaliza textos para comparaci√≥n (min√∫sculas, espacios, unidades)
- `calculate_relevance_score()`: Calcula score 0-100 de relevancia
- `format_price()`: Formatea precios consistentemente

**Algoritmo de Scoring:**
- 50 puntos por similitud general del texto (SequenceMatcher)
- 50 puntos por coincidencia de palabras clave
- +10 puntos bonus si todas las palabras est√°n presentes
- Threshold: 60/100 para considerar resultado relevante

**Ejemplos de Funcionamiento:**
```
B√∫squeda: "Lavadora LG 17Kg"
T√≠tulo: "Lavadora LG 17 Kg Carga Superior"
Score: 94/100 ‚úÖ Relevante

B√∫squeda: "Lavadora LG 17Kg"
T√≠tulo: "Nevera Samsung 300L"
Score: 17/100 ‚ùå No relevante

B√∫squeda: "iPhone 14"
T√≠tulo: "iPhone 14 Pro Max 256GB"
Score: 88/100 ‚úÖ Relevante
```

**Impacto:** Filtra resultados irrelevantes autom√°ticamente.

---

### 4. ‚úÖ Normalizaci√≥n de Texto Mejorada
**Incluido en:** `scrapers/text_utils.py`

**Transformaciones:**
- Min√∫sculas: "LAVADORA" ‚Üí "lavadora"
- Espacios m√∫ltiples: "LG    17  Kg" ‚Üí "LG 17Kg"
- Unidades sin espacio: "17 Kg" ‚Üí "17kg", "300 L" ‚Üí "300l"
- Elimina caracteres especiales pero preserva n√∫meros

**Impacto:** Mejora la comparaci√≥n de b√∫squedas con diferentes formatos.

---

## Problema Pendiente: Error 403 (Forbidden) üö´

### Situaci√≥n Actual
Ambos sitios (√âxito y Homecenter) est√°n bloqueando las solicitudes con error 403, incluso con headers mejorados.

### Causa
Protecci√≥n anti-bot avanzada:
- Cloudflare o similar
- Verificaci√≥n de JavaScript
- Fingerprinting del navegador
- An√°lisis de comportamiento

### Soluciones Posibles

#### Opci√≥n 1: Selenium/Playwright (Recomendado) üéØ
**Ventajas:**
- Simula navegador real con JavaScript
- Alta tasa de √©xito
- Control total

**Implementaci√≥n:**
```bash
pip install selenium webdriver-manager
```

**Requiere:**
- ChromeDriver/GeckoDriver
- M√°s recursos (RAM, CPU)
- M√°s lento que requests

---

#### Opci√≥n 2: Servicios de Scraping (M√°s Simple) üí∞
Usar servicios especializados:
- **ScraperAPI** (https://scraperapi.com)
- **ScrapingBee** (https://scrapingbee.com)
- **Bright Data** (https://brightdata.com)

**Ventajas:**
- Bypass autom√°tico de anti-bot
- Proxies rotativos incluidos
- No requiere Selenium

**Desventajas:**
- Costo mensual ($29-99/mes t√≠picamente)
- L√≠mite de requests

---

#### Opci√≥n 3: Proxies Rotativos üîÑ
Usar proxies para rotar IPs:
- Proxies residenciales
- Servicios como Bright Data, Oxylabs

**Ventajas:**
- M√°s dif√≠cil de bloquear

**Desventajas:**
- Costo adicional
- Puede no ser suficiente si hay verificaci√≥n JS

---

#### Opci√≥n 4: APIs Oficiales (Ideal) üèÜ
Contactar a los sitios para acceso a APIs.

**Ventajas:**
- Legalmente seguro
- Datos estructurados
- Sin bloqueos

**Desventajas:**
- Puede no estar disponible
- Proceso de aprobaci√≥n

---

## Pr√≥ximos Pasos Recomendados

### Fase 2: Resolver Error 403
**Opci√≥n A - Selenium (Open Source):**
1. Instalar: `pip install selenium webdriver-manager`
2. Crear `scrapers/selenium_scraper.py`
3. Modificar configuraci√≥n para usar Selenium en sitios bloqueados

**Opci√≥n B - Servicio de Scraping (M√°s r√°pido):**
1. Registrarse en ScraperAPI o similar
2. Modificar scrapers para usar su API
3. Configurar API key

### Fase 3: Scrapers Robustos
- Mejorar selectores XPath de Homecenter
- Implementar retry con backoff exponencial
- Agregar logging estructurado

### Fase 4: API REST
- Implementar API con FastAPI
- Endpoints para b√∫squeda y comparaci√≥n
- Documentaci√≥n Swagger

---

## Testing de las Mejoras

Para validar que las mejoras funcionan correctamente:

```bash
# Test del sistema de scoring
python3 -c "
from scrapers.text_utils import calculate_relevance_score

score, relevant = calculate_relevance_score('iPhone 14', 'iPhone 14 Pro Max')
print(f'Score: {score}/100 - Relevante: {relevant}')
"

# Test de b√∫squeda (dar√° 403 pero ver√°s las mejoras en logs)
echo -e "on-demand\nLavadora LG" | python3 main.py
```

---

## Archivos Modificados en Fase 1

```
‚úÖ scrapers/generic_scrapers.py     - Headers mejorados, scoring integrado
‚úÖ scrapers/graphql_scraper.py      - Headers mejorados, scoring integrado
‚úÖ scrapers/text_utils.py           - NUEVO - Utilidades de texto y scoring
‚úÖ config_sitios.json               - Filtro de categor√≠a eliminado
‚úÖ .gitignore                       - Archivos de cache ignorados
```

---

## Conclusi√≥n

**‚úÖ Completado:**
- Sistema de scoring de relevancia (60% threshold)
- Normalizaci√≥n de texto avanzada
- Headers HTTP mejorados
- B√∫squeda sin restricci√≥n de categor√≠a

**‚ö†Ô∏è Bloqueado por:**
- Error 403 de ambos sitios web
- Protecci√≥n anti-bot avanzada

**üéØ Siguiente paso recomendado:**
Implementar Selenium o usar servicio de scraping para resolver el bloqueo 403.

¬øDeseas que implemente Selenium (Fase 2) o prefieres explorar otra opci√≥n?
